---
name: vision
description: Computer vision - screenshots, screen analysis, and GUI automation via pyautogui.
metadata: {"nanobot":{"emoji":"üëÅÔ∏è","requires":{"python":["mss","pyautogui","Pillow","anthropic","google-generativeai"]}}}
---

# Vision

Control computer via screenshots and GUI automation.

## Fallback Architecture

Vision Analyzer –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–ø–æ—á–∫—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: **Claude ‚Üí Gemini ‚Üí None**.

- **Claude (anthropic)** ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –º–æ–¥–µ–ª—å `claude-3-5-sonnet-20241022`
- **Gemini (google)** ‚Äî fallback –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude –∏–ª–∏ –æ—à–∏–±–∫–µ
- **None** ‚Äî –µ—Å–ª–∏ –æ–±–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã

Screenshots —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `~/.nanobot/screenshots/`.

## Requirements

```bash
pip install mss pyautogui Pillow anthropic google-generativeai
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

| –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è        | –†–æ–ª—å     | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|-------------------|----------|-----------|
| `ANTHROPIC_API_KEY` | Claude   | –û—Å–Ω–æ–≤–Ω–æ–π  |
| `GEMINI_API_KEY`   | Gemini   | Fallback  |

–ö–æ–ø–∏—Ä—É–π—Ç–µ `.env.example` –≤ `.env` –∏ —É–∫–∞–∂–∏—Ç–µ –∫–ª—é—á–∏.

## Commands

### Screenshot + AI Analysis üëÅÔ∏è

**"/vision —á—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ?"** ‚Äî –°–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:

```python
from nanobot.skills.vision import vision

# –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑
result = vision.analyze_screenshot()
print(result)  # AI –æ–ø–∏—Å—ã–≤–∞–µ—Ç —á—Ç–æ –≤–∏–¥–∏—Ç

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å
result = vision.analyze_screenshot("–ì–¥–µ –∫–Ω–æ–ø–∫–∞ '–°–æ—Ö—Ä–∞–Ω–∏—Ç—å'? –î–∞–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.")

# –î–≤—É—Ö—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å
path = vision.capture_screenshot()  # –°–Ω–∏–º–æ–∫
analysis = vision.analyze_screenshot("–ï—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∏?")  # –ê–Ω–∞–ª–∏–∑
```

**–ö–æ–º–∞–Ω–¥—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**
- `/vision —á—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ?` ‚Äî –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑
- `/vision –≥–¥–µ –∫–Ω–æ–ø–∫–∞ "X"?` ‚Äî –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–∞
- `/vision –µ—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∏?` ‚Äî –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏
- `/vision –ø—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç` ‚Äî OCR –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

### –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã

| –ü—Ä–æ–≤–∞–π–¥–µ—Ä | –ú–æ–¥–µ–ª—å | –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è |
|-----------|--------|----------------------|
| **Claude** (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) | claude-3-5-sonnet-20241022 | `ANTHROPIC_API_KEY` |
| **Gemini** (fallback) | gemini-1.5-flash | `GEMINI_API_KEY` |

### Vision Analyzer API

```python
from nanobot.skills.vision.analyzer import VisionAnalyzer, analyze_screenshot, get_analyzer

# Singleton analyzer (—á–∏—Ç–∞–µ—Ç –∫–ª—é—á–∏ –∏–∑ env)
analyzer = get_analyzer()
print(analyzer.get_provider())  # "anthropic" –∏–ª–∏ "google" –∏–ª–∏ None

# –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
text = analyzer.analyze("C:/tmp/screen.png", "–û–ø–∏—à–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –Ω–∞–π–¥–∏ –æ—à–∏–±–∫–∏")

# –ë—ã—Å—Ç—Ä—ã–π –≤—ã–∑–æ–≤: —Å–∫—Ä–∏–Ω—à–æ—Ç + –∞–Ω–∞–ª–∏–∑
quick = analyze_screenshot("–ï—Å—Ç—å –ª–∏ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –∫–Ω–æ–ø–∫–∞ '–°–æ—Ö—Ä–∞–Ω–∏—Ç—å'?")
print(quick)
```

### Mouse Control
```python
# Move mouse to coordinates
pyautogui.moveTo(100, 200, duration=0.5)

# Click
pyautogui.click(100, 200)
pyautogui.rightClick(100, 200)
pyautogui.doubleClick(100, 200)

# Drag
pyautogui.dragTo(300, 400, duration=1)
```

### Keyboard
```python
# Type text
pyautogui.typewrite("Hello World", interval=0.01)

# Press keys
pyautogui.press('enter')
pyautogui.hotkey('ctrl', 'c')
pyautogui.hotkey('alt', 'tab')
```

### Screen Info
```python
# Get screen size
width, height = pyautogui.size()  # (1920, 1080)

# Get mouse position
x, y = pyautogui.position()

# Take screenshot
import mss
with mss.mss() as sct:
    screenshot = sct.grab(sct.monitors[1])
```

## Examples

**"What's on my screen?"**
```python
vision_capture_and_analyze("Describe what you see on the screen")
```

**"Open Chrome and go to gmail"**
```python
# Find Chrome icon and click
pyautogui.click(100, 100)  # Chrome position
pyautogui.sleep(1)
pyautogui.click(500, 50)   # Address bar
pyautogui.typewrite("gmail.com")
pyautogui.press('enter')
```

**"Watch for errors"**
```python
# Capture every 5 seconds and check for "Error" text
while True:
    img = vision_capture()
    if "error" in vision_ocr(img).lower():
        send_telegram("Error detected!")
    pyautogui.sleep(5)
```

## Safety

- Always add `duration` to mouse movements
- Use `pyautogui.FAILSAFE = True` (move to corner to abort)
- Confirm before destructive actions
- Screenshots saved to `~/.nanobot/screenshots/`
